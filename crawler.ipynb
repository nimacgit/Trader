{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T15:46:59.030478Z",
     "start_time": "2019-10-10T15:46:55.368512Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%writefile crawler.py\n",
    "\n",
    "# !pip3 install -q selenium bs4\n",
    "# !pip3 install jdatetime\n",
    "# !pip3 install khayyam\n",
    "!pip3 install -q urllib3\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !pip install nbresuse\n",
    "# !pip install selenium, bs4\n",
    "# from selenium import webdriver\n",
    "# from bs4 import BeautifulSoup as bs\n",
    "from requests import Session, Request\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "from khayyam import JalaliDate, JalaliDatetime\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "parentPageUrl = 'http://www.tsetmc.com/Loader.aspx?ParTree=15131F'\n",
    "saveLocation = \"../xcels/\"\n",
    "xcelBaseUrl = \"http://members.tsetmc.com/tsev2/excel/MarketWatchPlus.aspx?d=\"\n",
    "session = Session()\n",
    "request = Request(\"Get\", parentPageUrl)\n",
    "prepared = session.prepare_request(request)\n",
    "respond = session.send(prepared, verify=False)\n",
    "\n",
    "\n",
    "def fetch(saveLocation, year, month, day):\n",
    "    global xcelBaseUrl\n",
    "    \n",
    "    with open(saveLocation + str(year) + \"-\" + str(month) + \"-\" + str(day) + \".xlsx\", 'wb') as f:\n",
    "        xcelUrl = xcelBaseUrl + str(year) + \"/\" + str(month) + \"/\" + str(day)\n",
    "        xcelRequest = Request(\"Get\", xcelUrl)\n",
    "        xcelPrepared = session.prepare_request(xcelRequest)\n",
    "        xcelRespond = session.send(xcelPrepared, verify=False, stream=True)\n",
    "        xcelRespond.raise_for_status()\n",
    "        for chunk in xcelRespond.iter_content(chunk_size=8192): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "            # f.flush()\n",
    "\n",
    "def crawl(startDate, endDate):\n",
    "    global saveLocation\n",
    "    \n",
    "    now = startDate\n",
    "    while now <= endDate:\n",
    "        jalaldate = JalaliDate(now)\n",
    "        year = jalaldate.year\n",
    "        month = jalaldate.month\n",
    "        day = jalaldate.day\n",
    "        if jalaldate.weekday() < 5 and not Path(saveLocation + str(year) + \"-\" + str(month) + \n",
    "                                                \"-\" + str(day) + \".xlsx\").is_file():\n",
    "            fetch(saveLocation=saveLocation, year=year, month=month, day=day)\n",
    "            time.sleep(5)\n",
    "        now = now + timedelta(days=1)\n",
    "        \n",
    "def crawlingThread(threadName, startDate):\n",
    "    endDateJalali = JalaliDate(year=1398, month=6, day=5)\n",
    "    while True:\n",
    "        if endDateJalali != JalaliDate.today():\n",
    "            endDateJalali = JalaliDate.today()\n",
    "            crawl(startDate, endDateJalali.todate())\n",
    "            startDate = endDateJalali.todate()\n",
    "            with open(saveLocation + \"crawlstat\", 'w') as statfile:\n",
    "                lastcheck = JalaliDatetime.now()\n",
    "                statfile.write(\"last check\")\n",
    "                statfile.write(str(lastcheck))\n",
    "                statfile.write(\"\\n\")\n",
    "                statfile.write(\"last crawl: \")\n",
    "                statfile.write(str(endDateJalali))\n",
    "                statfile.write(\"\\n\")\n",
    "        time.sleep(24 * 3600)\n",
    "\n",
    "# startDate = JalaliDate(year=1380, month=1, day=1).todate()\n",
    "startDate = JalaliDate(year=1398, month=7, day=10).todate()\n",
    "crawlThread = multiprocessing.Process(target=crawlingThread, args=(\"Thread-crawl\", startDate))\n",
    "crawlThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:57:00.212057Z",
     "start_time": "2019-09-13T09:22:27.565Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T15:46:59.348766Z",
     "start_time": "2019-10-10T15:46:59.226726Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:20:19.213339Z",
     "start_time": "2019-08-30T08:20:19.199057Z"
    }
   },
   "outputs": [],
   "source": [
    "# file_object = open(\"user.pkl\", 'ab')\n",
    "# # pickle.dump(requests.utils.dict_from_cookiejar(resp.cookies), file_object)\n",
    "\n",
    "# soup = bs(resp.text, 'html.parser')\n",
    "# name = soup.find_all(itemprop='name')\n",
    "# name = [x.get_text() for x in name]\n",
    "# moredis = soup.findAll(\"p\", {\"class\": \"prd-desc more\"})\n",
    "# moredis = [x.get_text() for x in moredis]\n",
    "# weight = soup.findAll(\"span\", {\"class\": \"unit\"})\n",
    "# weight = [x.get_text() for x in weight]\n",
    "\n",
    "# import datetime\n",
    "# now = datetime.datetime.now()\n",
    "\n",
    "# with open('somefile') as f:\n",
    "#     cookies = requests.utils.cookiejar_from_dict(pickle.load(f))\n",
    "#     session = requests.session(cookies=cookies)\n",
    "\n",
    "# from http.cookies import SimpleCookie\n",
    "# rawdata = 'Cookie: _ga=GA1.2.969355752.1534482039;' \\\n",
    "#           ' JSESSIONID=nM0Rmitqyzs4sWMMdOBXB5BDbq09pS3ilLqwUJOV1bCZv_BxQgHS!484861232'\n",
    "# cookie = SimpleCookie()\n",
    "# cookie.load(rawdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
