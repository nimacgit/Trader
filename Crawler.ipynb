{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:20:18.814158Z",
     "start_time": "2019-08-30T08:20:14.460226Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpcadminuser/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install -q selenium bs4\n",
    "# !pip3 install jdatetime\n",
    "# !pip3 install khayyam\n",
    "!pip3 install -q urllib3\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !pip install nbresuse\n",
    "from selenium import webdriver\n",
    "from requests import Session, Request\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import jdatetime\n",
    "from khayyam import JalaliDate, JalaliDatetime\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/jbennetcodes/dealing-with-datetimes-like-a-pro-in-pandas-b80d3d808a7f\n",
    "https://towardsdatascience.com/basic-time-series-manipulation-with-pandas-4432afee64ea\n",
    "https://medium.com/@aroussi/fast-data-store-for-pandas-time-series-data-using-pystore-89d9caeef4e2\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:20:18.947731Z",
     "start_time": "2019-08-30T08:20:18.822464Z"
    }
   },
   "outputs": [],
   "source": [
    "parentPageUrl = 'http://www.tsetmc.com/Loader.aspx?ParTree=15131F'\n",
    "saveLocation = \"../xcels/\"\n",
    "xcelBaseUrl = \"http://members.tsetmc.com/tsev2/excel/MarketWatchPlus.aspx?d=\"\n",
    "\n",
    "session = Session()\n",
    "request = Request(\"Get\", parentPageUrl)\n",
    "prepared = session.prepare_request(request)\n",
    "respond = session.send(prepared, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:20:18.967664Z",
     "start_time": "2019-08-30T08:20:18.955046Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch(saveLocation, year, month, day):\n",
    "    global xcelBaseUrl\n",
    "    \n",
    "    with open(saveLocation + str(year) + \"-\" + str(month) + \"-\" + str(day) + \".xlsx\", 'wb') as f:\n",
    "        xcelUrl = xcelBaseUrl + str(year) + \"/\" + str(month) + \"/\" + str(day)\n",
    "        xcelRequest = Request(\"Get\", xcelUrl)\n",
    "        xcelPrepared = session.prepare_request(xcelRequest)\n",
    "        xcelRespond = session.send(xcelPrepared, verify=False, stream=True)\n",
    "        xcelRespond.raise_for_status()\n",
    "        for chunk in xcelRespond.iter_content(chunk_size=8192): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "            # f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:20:19.051485Z",
     "start_time": "2019-08-30T08:20:18.971767Z"
    }
   },
   "outputs": [],
   "source": [
    "def crawl(startDate, endDate):\n",
    "    global saveLocation\n",
    "    \n",
    "    now = startDate\n",
    "    while now <= endDate:\n",
    "        jalaldate = JalaliDate(now)\n",
    "        year = jalaldate.year\n",
    "        month = jalaldate.month\n",
    "        day = jalaldate.day\n",
    "        if jalaldate.weekday() < 5 and not Path(saveLocation + str(year) + \"-\" + str(month) + \n",
    "                                                \"-\" + str(day) + \".xlsx\").is_file():\n",
    "            fetch(saveLocation=saveLocation, year=year, month=month, day=day)\n",
    "            time.sleep(5)\n",
    "        now = now + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:20:19.181750Z",
     "start_time": "2019-08-30T08:20:19.055219Z"
    }
   },
   "outputs": [],
   "source": [
    "def crawlingThread(threadName, startDate):\n",
    "    endDateJalali = JalaliDate(year=1398, month=6, day=5)\n",
    "    while True:\n",
    "        if endDateJalali != JalaliDate.today():\n",
    "            endDateJalali = JalaliDate.today()\n",
    "            crawl(startDate, endDateJalali.todate())\n",
    "            startDate = endDateJalali.todate()\n",
    "            with open(saveLocation + \"crawlstat\", 'w') as statfile:\n",
    "                lastcheck = JalaliDatetime.now()\n",
    "                statfile.write(\"last check\")\n",
    "                statfile.write(str(lastcheck))\n",
    "                statfile.write(\"\\n\")\n",
    "                statfile.write(\"last crawl: \")\n",
    "                statfile.write(str(endDateJalali))\n",
    "                statfile.write(\"\\n\")\n",
    "        time.sleep(24 * 3600)\n",
    "\n",
    "# startDate = JalaliDate(year=1380, month=1, day=1).todate()\n",
    "# startDate = JalaliDate(year=1398, month=6, day=1).todate()\n",
    "# endDate = JalaliDate(year=1398, month=6, day=5).todate()\n",
    "startDate = JalaliDate(year=1398, month=6, day=1).todate()\n",
    "crawlThread = multiprocessing.Process(target=crawlingThread, args=(\"Thread-crawl\", startDate))\n",
    "crawlThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:20:19.213339Z",
     "start_time": "2019-08-30T08:20:19.199057Z"
    }
   },
   "outputs": [],
   "source": [
    "# file_object = open(\"user.pkl\", 'ab')\n",
    "# # pickle.dump(requests.utils.dict_from_cookiejar(resp.cookies), file_object)\n",
    "\n",
    "# soup = bs(resp.text, 'html.parser')\n",
    "# name = soup.find_all(itemprop='name')\n",
    "# name = [x.get_text() for x in name]\n",
    "# moredis = soup.findAll(\"p\", {\"class\": \"prd-desc more\"})\n",
    "# moredis = [x.get_text() for x in moredis]\n",
    "# weight = soup.findAll(\"span\", {\"class\": \"unit\"})\n",
    "# weight = [x.get_text() for x in weight]\n",
    "\n",
    "# import datetime\n",
    "# now = datetime.datetime.now()\n",
    "\n",
    "# with open('somefile') as f:\n",
    "#     cookies = requests.utils.cookiejar_from_dict(pickle.load(f))\n",
    "#     session = requests.session(cookies=cookies)\n",
    "\n",
    "# from http.cookies import SimpleCookie\n",
    "# rawdata = 'Cookie: _ga=GA1.2.969355752.1534482039;' \\\n",
    "#           ' JSESSIONID=nM0Rmitqyzs4sWMMdOBXB5BDbq09pS3ilLqwUJOV1bCZv_BxQgHS!484861232'\n",
    "# cookie = SimpleCookie()\n",
    "# cookie.load(rawdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
